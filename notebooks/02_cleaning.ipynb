{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1c0c98-8c54-41fd-88c0-e4c6d87b2a00",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this notebook, I will clean the 9 raw Olist datasets to prepare them for analysis.  \n",
    "The main tasks include:\n",
    "- Handling missing values\n",
    "- Fixing inconsistent column names\n",
    "- Dropping duplicates where necessary\n",
    "- Converting data types (e.g., dates)\n",
    "- Standardizing categorical values\n",
    "\n",
    "The datasets being cleaned are:\n",
    "1. Orders  \n",
    "2. Customers  \n",
    "3. Order Items  \n",
    "4. Payments  \n",
    "5. Products  \n",
    "6. Sellers  \n",
    "7. Reviews  \n",
    "8. Geolocation  \n",
    "9. Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46d06a0c-641d-4dc8-9940-6ca211d6222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raw data loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "DATA_CLEANED = Path(\"../data/cleaned\")\n",
    "DATA_CLEANED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "orders = pd.read_csv(DATA_RAW / \"olist_orders_dataset.csv\")\n",
    "customers = pd.read_csv(DATA_RAW / \"olist_customers_dataset.csv\")\n",
    "order_items = pd.read_csv(DATA_RAW / \"olist_order_items_dataset.csv\")\n",
    "payments = pd.read_csv(DATA_RAW / \"olist_order_payments_dataset.csv\")\n",
    "products = pd.read_csv(DATA_RAW / \"olist_products_dataset.csv\")\n",
    "sellers = pd.read_csv(DATA_RAW / \"olist_sellers_dataset.csv\")\n",
    "reviews = pd.read_csv(DATA_RAW / \"olist_order_reviews_dataset.csv\")\n",
    "geolocation = pd.read_csv(DATA_RAW / \"olist_geolocation_dataset.csv\")\n",
    "categories = pd.read_csv(DATA_RAW / \"product_category_name_translation.csv\")\n",
    "\n",
    "print(\"âœ… Raw data loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826ef0b-e5fb-4d64-9e95-104b3f0fba23",
   "metadata": {},
   "source": [
    "## Orders\n",
    "The orders dataset contains purchase and delivery information.  \n",
    "Cleaning tasks:\n",
    "- Ensure date columns are in datetime format.\n",
    "- Keep all rows (missing delivery dates often mean the order was canceled).\n",
    "- Drop duplicates if any.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "544a42c4-6558-4ae9-aff2-102f4cb18db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 8 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       99441 non-null  object        \n",
      " 1   customer_id                    99441 non-null  object        \n",
      " 2   order_status                   99441 non-null  object        \n",
      " 3   order_purchase_timestamp       99441 non-null  datetime64[ns]\n",
      " 4   order_approved_at              99281 non-null  datetime64[ns]\n",
      " 5   order_delivered_carrier_date   97658 non-null  datetime64[ns]\n",
      " 6   order_delivered_customer_date  96476 non-null  datetime64[ns]\n",
      " 7   order_estimated_delivery_date  99441 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](5), object(3)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    " # Orders cleaning\n",
    "orders['order_purchase_timestamp'] = pd.to_datetime(orders['order_purchase_timestamp'])\n",
    "orders['order_approved_at'] = pd.to_datetime(orders['order_approved_at'])\n",
    "orders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date'])\n",
    "orders['order_delivered_customer_date'] = pd.to_datetime(orders['order_delivered_customer_date'])\n",
    "orders['order_estimated_delivery_date'] = pd.to_datetime(orders['order_estimated_delivery_date'])\n",
    "\n",
    "# Drop duplicates\n",
    "orders.drop_duplicates(inplace=True)\n",
    "\n",
    "orders.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c3c94-b0a5-4216-8f0d-62bf804e3a20",
   "metadata": {},
   "source": [
    "## Customers\n",
    "The customers dataset links unique customers to orders.  \n",
    "Cleaning tasks:\n",
    "- Remove duplicates.\n",
    "- Handle missing values if any (should be rare).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46f8c2df-a44b-432e-8040-d1f18e378007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99441 entries, 0 to 99440\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   customer_id               99441 non-null  object\n",
      " 1   customer_unique_id        99441 non-null  object\n",
      " 2   customer_zip_code_prefix  99441 non-null  int64 \n",
      " 3   customer_city             99441 non-null  object\n",
      " 4   customer_state            99441 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Customers cleaning\n",
    "customers.drop_duplicates(inplace=True)\n",
    "\n",
    "customers.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efab375-6706-4669-b5c3-30b043adfae6",
   "metadata": {},
   "source": [
    "## Order Items\n",
    "The order items dataset links products to orders.  \n",
    "Cleaning tasks:\n",
    "- Drop duplicates.\n",
    "- Ensure `price` and `freight_value` are non-negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f133224-1d41-484e-9f94-bcf53e263c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Order items cleaning\n",
    "order_items.drop_duplicates(inplace=True)\n",
    "\n",
    "# Ensure no negative values\n",
    "order_items = order_items[(order_items['price'] >= 0) & (order_items['freight_value'] >= 0)]\n",
    "\n",
    "order_items.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d3eb1-64f2-4c9a-8e20-c0932f419947",
   "metadata": {},
   "source": [
    "## Payments\n",
    "The payments dataset contains payment details.  \n",
    "Cleaning tasks:\n",
    "- Drop duplicates.\n",
    "- Remove rows where payment values are negative (if any).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74eca24-5e65-4568-8518-fea43c23c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103886 entries, 0 to 103885\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              103886 non-null  object \n",
      " 1   payment_sequential    103886 non-null  int64  \n",
      " 2   payment_type          103886 non-null  object \n",
      " 3   payment_installments  103886 non-null  int64  \n",
      " 4   payment_value         103886 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Payments cleaning\n",
    "payments.drop_duplicates(inplace=True)\n",
    "payments = payments[payments['payment_value'] >= 0]\n",
    "\n",
    "payments.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c7a7a-d205-4ebf-a986-6be72796778d",
   "metadata": {},
   "source": [
    "## Products\n",
    "The products dataset has metadata about products.  \n",
    "Cleaning tasks:\n",
    "- Fix column name typos (`lenght` â†’ `length`).\n",
    "- Fill missing category names with `\"unknown\"`.\n",
    "- Fill missing numeric values with the median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887a8320-d7d0-4e97-b728-244cc914e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32951 non-null  object \n",
      " 2   product_name_length         32951 non-null  float64\n",
      " 3   product_description_length  32951 non-null  float64\n",
      " 4   product_photos_qty          32951 non-null  float64\n",
      " 5   product_weight_g            32951 non-null  float64\n",
      " 6   product_length_cm           32951 non-null  float64\n",
      " 7   product_height_cm           32951 non-null  float64\n",
      " 8   product_width_cm            32951 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Fill missing category names with \"unknown\"\n",
    "products[\"product_category_name\"] = products[\"product_category_name\"].fillna(\"unknown\")\n",
    "\n",
    "# List of numerical columns to clean\n",
    "num_cols = [\n",
    "    \"product_name_length\",\n",
    "    \"product_description_length\",\n",
    "    \"product_photos_qty\",\n",
    "    \"product_weight_g\",\n",
    "    \"product_length_cm\",\n",
    "    \"product_height_cm\",\n",
    "    \"product_width_cm\"\n",
    "]\n",
    "\n",
    "# Fill missing numerical values with the median of each column\n",
    "for col in num_cols:\n",
    "    products[col] = products[col].fillna(products[col].median())\n",
    "\n",
    "products.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb44051-70b4-4367-b08c-4cb0b1b1769a",
   "metadata": {},
   "source": [
    "## Sellers\n",
    "The sellers dataset contains seller information.  \n",
    "Cleaning tasks:\n",
    "- Drop duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82841dff-c290-469a-b2f4-eab37320b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3095 entries, 0 to 3094\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   seller_id               3095 non-null   object\n",
      " 1   seller_zip_code_prefix  3095 non-null   int64 \n",
      " 2   seller_city             3095 non-null   object\n",
      " 3   seller_state            3095 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 96.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sellers cleaning\n",
    "sellers.drop_duplicates(inplace=True)\n",
    "\n",
    "sellers.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c8f0f-f0ca-4dd1-8b65-458218cffedb",
   "metadata": {},
   "source": [
    "## Reviews\n",
    "The reviews dataset contains customer reviews and ratings.  \n",
    "Cleaning tasks:\n",
    "- Convert date columns to datetime.\n",
    "- Drop duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48d51aad-fac8-490e-af97-436c2b9f93e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 7 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   review_id                99224 non-null  object        \n",
      " 1   order_id                 99224 non-null  object        \n",
      " 2   review_score             99224 non-null  int64         \n",
      " 3   review_comment_title     11568 non-null  object        \n",
      " 4   review_comment_message   40977 non-null  object        \n",
      " 5   review_creation_date     99224 non-null  datetime64[ns]\n",
      " 6   review_answer_timestamp  99224 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Reviews cleaning\n",
    "reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'])\n",
    "reviews['review_answer_timestamp'] = pd.to_datetime(reviews['review_answer_timestamp'])\n",
    "reviews.drop_duplicates(inplace=True)\n",
    "\n",
    "reviews.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df79b5d-6d52-4791-9b92-406bce1a4b41",
   "metadata": {},
   "source": [
    "## Geolocation\n",
    "The geolocation dataset contains postal codes and coordinates.  \n",
    "Cleaning tasks:\n",
    "- Drop duplicates.\n",
    "- Standardize postal codes (remove spaces, keep only numbers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5671a932-d756-4ce2-9fcf-23526e9367cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 738332 entries, 0 to 1000161\n",
      "Data columns (total 5 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   geolocation_zip_code_prefix  738332 non-null  object \n",
      " 1   geolocation_lat              738332 non-null  float64\n",
      " 2   geolocation_lng              738332 non-null  float64\n",
      " 3   geolocation_city             738332 non-null  object \n",
      " 4   geolocation_state            738332 non-null  object \n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 33.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Geolocation cleaning\n",
    "geolocation.drop_duplicates(inplace=True)\n",
    "geolocation['geolocation_zip_code_prefix'] = geolocation['geolocation_zip_code_prefix'].astype(str).str.strip()\n",
    "\n",
    "geolocation.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2093a5a-ad32-4180-8161-f0129489e5f6",
   "metadata": {},
   "source": [
    "## Categories\n",
    "The categories dataset maps Portuguese category names to English.  \n",
    "Cleaning tasks:\n",
    "- Drop duplicates.\n",
    "- Fill missing translations with `\"unknown\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af00889a-e657-4013-8e5e-8b4e912024aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71 entries, 0 to 70\n",
      "Data columns (total 2 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   product_category_name          71 non-null     object\n",
      " 1   product_category_name_english  71 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Categories cleaning\n",
    "categories['product_category_name_english'] = categories['product_category_name_english'].fillna(\"unknown\")\n",
    "\n",
    "categories.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31961c74-8eea-48e0-9c9a-058c881bf227",
   "metadata": {},
   "source": [
    "## Cleaning Summary\n",
    "\n",
    "To confirm the success of the cleaning process, I will print out the number of rows and columns for each dataset after cleaning.  \n",
    "This helps ensure:\n",
    "- No accidental data loss.\n",
    "- Duplicates were removed.\n",
    "- Missing values were handled appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "544bb428-5eca-4160-8d5a-b54de5ef072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dataset Summary After Cleaning:\n",
      "\n",
      "Orders: 99441 rows, 8 columns\n",
      "Customers: 99441 rows, 5 columns\n",
      "Order Items: 112650 rows, 7 columns\n",
      "Payments: 103886 rows, 5 columns\n",
      "Products: 32951 rows, 9 columns\n",
      "Sellers: 3095 rows, 4 columns\n",
      "Reviews: 99224 rows, 7 columns\n",
      "Geolocation: 738332 rows, 5 columns\n",
      "Categories: 71 rows, 2 columns\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of datasets\n",
    "datasets = {\n",
    "    \"Orders\": orders,\n",
    "    \"Customers\": customers,\n",
    "    \"Order Items\": order_items,\n",
    "    \"Payments\": payments,\n",
    "    \"Products\": products,\n",
    "    \"Sellers\": sellers,\n",
    "    \"Reviews\": reviews,\n",
    "    \"Geolocation\": geolocation,\n",
    "    \"Categories\": categories\n",
    "}\n",
    "\n",
    "# Print a summary of cleaned datasets\n",
    "print(\"ðŸ“Š Dataset Summary After Cleaning:\\n\")\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name}: {df.shape[0]} rows, {df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b73524-98aa-4f4c-82a6-3b136527ccdf",
   "metadata": {},
   "source": [
    "## Export Cleaned Datasets\n",
    "\n",
    "After cleaning, I will export each dataset into the `data/processed/` folder.  \n",
    "This ensures:\n",
    "- The raw data is preserved in `data/raw/`\n",
    "- The cleaned versions are stored separately\n",
    "- Future analysis notebooks can simply load the cleaned data instead of repeating the cleaning steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fff6abb7-75b1-4bcc-a97e-1ef8c324ebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All cleaned datasets have been exported to /data/processed/\n"
     ]
    }
   ],
   "source": [
    "# Define output folder\n",
    "output_path = \"../data/processed/\"\n",
    "\n",
    "# Save each cleaned dataset to CSV\n",
    "orders.to_csv(output_path + \"orders_cleaned.csv\", index=False)\n",
    "customers.to_csv(output_path + \"customers_cleaned.csv\", index=False)\n",
    "order_items.to_csv(output_path + \"order_items_cleaned.csv\", index=False)\n",
    "payments.to_csv(output_path + \"payments_cleaned.csv\", index=False)\n",
    "products.to_csv(output_path + \"products_cleaned.csv\", index=False)\n",
    "sellers.to_csv(output_path + \"sellers_cleaned.csv\", index=False)\n",
    "reviews.to_csv(output_path + \"reviews_cleaned.csv\", index=False)\n",
    "geolocation.to_csv(output_path + \"geolocation_cleaned.csv\", index=False)\n",
    "categories.to_csv(output_path + \"categories_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"âœ… All cleaned datasets have been exported to /data/processed/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee93de-a284-48ec-ae27-925012573f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
